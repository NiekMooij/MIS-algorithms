{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fp/k37g19px2jn5bjfqsk39c2sh0000gn/T/ipykernel_16076/3735179892.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import MIS_algorithms as MIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Erdos-Renyi graphs with different sizes and probabilities of connection\n",
    "\n",
    "def generate_row_erdos_renyi(size, p):\n",
    "        \n",
    "    G = MIS.erdos_renyi(size, p, connected=True)\n",
    "    \n",
    "    new_row = {\n",
    "                'type': 'erdos_renyi',\n",
    "                'size': len(G),\n",
    "                'p_connection': p,\n",
    "                'vertices': G.nodes(), \n",
    "                'edges': G.edges(), \n",
    "                'exact_output': None, \n",
    "                'exact_time': None,\n",
    "                'LV_output': None, \n",
    "                'LV_time': None, \n",
    "                'continuation_output': None, \n",
    "                'continuation_time': None, \n",
    "                'greedy_output': None, \n",
    "                'greedy_time': None\n",
    "                }\n",
    "\n",
    "    return new_row\n",
    "\n",
    "number_of_runs = 1000\n",
    "\n",
    "rows = [ generate_row_erdos_renyi(60, np.log(60) / 60 +  k * (1 - np.log(60) / 60) / 10) for k in range(11) for i in range(number_of_runs) ]\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(sys.path[0], 'data_empty/erdos_renyi_probability.csv'), index=False)\n",
    "df.to_pickle(os.path.join(sys.path[0], 'data_empty/erdos_renyi_probability.pkl'))\n",
    "\n",
    "size_domain = [ 10, 16, 36, 46, 66, 90, 130, 160, 200 ]\n",
    "rows = [ generate_row_erdos_renyi(size, np.log(size) / size) for size in size_domain for i in range(number_of_runs)]\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(sys.path[0], 'data_empty/erdos_renyi_size_sparse.csv'), index=False)\n",
    "df.to_pickle(os.path.join(sys.path[0], 'data_empty/erdos_renyi_size_sparse.pkl'))\n",
    "\n",
    "size_domain = [ 10, 16, 36, 46, 66, 90, 130, 160, 200 ]\n",
    "rows = [ generate_row_erdos_renyi(size, 1/2) for size in size_domain for i in range(number_of_runs)]\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(sys.path[0], 'data_empty/erdos_renyi_size_dense.csv'), index=False)\n",
    "df.to_pickle(os.path.join(sys.path[0], 'data_empty/erdos_renyi_size_dense.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random bipartite graphs with different sizes and probabilities of connection\n",
    "\n",
    "def generate_row_bipartite(size_a, size_b, p):\n",
    "        \n",
    "    G = MIS.random_bipartite(size_a, size_b, p, connected=True)\n",
    "    \n",
    "    new_row = {\n",
    "                'type': 'random_bipartite',\n",
    "                'size1': int(len(G) / 2), \n",
    "                'size2': int(len(G) / 2), \n",
    "                'p_connection': p,\n",
    "                'vertices': G.nodes(), \n",
    "                'edges': G.edges(), \n",
    "                'exact_output': None, \n",
    "                'exact_time': None,\n",
    "                'LV_output': None, \n",
    "                'LV_time': None, \n",
    "                'continuation_output': None, \n",
    "                'continuation_time': None, \n",
    "                'greedy_output': None, \n",
    "                'greedy_time': None\n",
    "                }\n",
    "\n",
    "    return new_row\n",
    "\n",
    "number_of_runs = 1000\n",
    "\n",
    "# Generate random bipartite graphs\n",
    "rows = [ generate_row_bipartite(30, 30, np.log(30) / 30 +  k * (1 - np.log(30) / 30) / 10) for k in range(11) for i in range(number_of_runs) ]\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(sys.path[0], 'data_empty/random_bipartite_probability.csv'), index=False)\n",
    "df.to_pickle(os.path.join(sys.path[0], 'data_empty/random_bipartite_probability.pkl'))\n",
    "\n",
    "size_domain = [ 10, 16, 36, 46, 66, 90, 130, 160, 200 ]\n",
    "rows = [ generate_row_bipartite(int(size/2), int(size/2), np.log(size/2) / (size/2)) for size in size_domain for i in range(number_of_runs)]\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(sys.path[0], 'data_empty/random_bipartite_size_sparse.csv'), index=False)\n",
    "df.to_pickle(os.path.join(sys.path[0], 'data_empty/random_bipartite_size_sparse.pkl'))\n",
    "\n",
    "size_domain = [ 10, 16, 36, 46, 66, 90, 130, 160, 200 ]\n",
    "rows = [ generate_row_bipartite(int(size/2), int(size/2), 1/2) for size in size_domain for i in range(number_of_runs)]\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(sys.path[0], 'data_empty/random_bipartite_size_dense.csv'), index=False)\n",
    "df.to_pickle(os.path.join(sys.path[0], 'data_empty/random_bipartite_size_dense.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random geometric graphs with different sizes and probabilities of connection\n",
    "\n",
    "def generate_row_geometric(size, p):\n",
    "    \n",
    "    G = MIS.random_geometric(size, p, connected=True)\n",
    "    \n",
    "    new_row = {\n",
    "                'type': 'random_geometric',\n",
    "                'size': len(G),\n",
    "                'r_radius': p,\n",
    "                'vertices': G.nodes(), \n",
    "                'edges': G.edges(), \n",
    "                'exact_output': None, \n",
    "                'exact_time': None,\n",
    "                'LV_output': None, \n",
    "                'LV_time': None, \n",
    "                'continuation_output': None, \n",
    "                'continuation_time': None, \n",
    "                'greedy_output': None, \n",
    "                'greedy_time': None\n",
    "                }\n",
    "\n",
    "    return new_row\n",
    "\n",
    "number_of_runs = 1000\n",
    "\n",
    "# Generate random geometric graphs\n",
    "rows = [ generate_row_geometric(60, 1.2*np.sqrt(np.log(60) / (np.pi * 60)) +  k * (np.sqrt(2) - 1.2*np.sqrt(np.log(60) / (np.pi * 60))) / 10) for k in range(11) for i in range(number_of_runs) ]\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(sys.path[0], 'data_empty/random_geometric_probability.csv'), index=False)\n",
    "df.to_pickle(os.path.join(sys.path[0], 'data_empty/random_geometric_probability.pkl'))\n",
    "\n",
    "size_domain = [ 10, 16, 36, 46, 66, 90, 130, 160, 200 ]\n",
    "rows = [ generate_row_geometric(size, 1.2*np.sqrt(np.log(size) / (np.pi * size))) for size in size_domain for i in range(number_of_runs)]\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(sys.path[0], 'data_empty/random_geometric_size_sparse.csv'), index=False)\n",
    "df.to_pickle(os.path.join(sys.path[0], 'data_empty/random_geometric_size_sparse.pkl'))\n",
    "\n",
    "size_domain = [ 10, 16, 36, 46, 66, 90, 130, 160, 200 ]\n",
    "rows = [ generate_row_geometric(size, 1/2) for size in size_domain for i in range(number_of_runs)]\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(sys.path[0], 'data_empty/random_geometric_size_dense.csv'), index=False)\n",
    "df.to_pickle(os.path.join(sys.path[0], 'data_empty/random_geometric_size_dense.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
